{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09334aeb",
   "metadata": {},
   "source": [
    "Skin cancer detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60eb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_digits, load_sample_images\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac117d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_images_fs, train_labels = next(train_generator)\n",
    "test_images_fs, test_labels = next(test_generator)\n",
    "#val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a62f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e2a4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3c4128",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82be8f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794ef6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124686d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336d1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b546b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9968b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78805466",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(train_labels, columns=['actinic_keratosis', 'basal_cell_carcinoma',\\\n",
    "            'dermatofibroma', 'melanoma', 'nevus', 'pigmented_benign_keratosis',\\\n",
    "            'seborrheic_keratosis', 'squamous_cell_carcinoma', 'vascular_lesion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c522939",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7572fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdf4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=dataframe.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bdc6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=pd.DataFrame(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f09127",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94da6aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums['%'] = ((sums[0] / 2239*100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9fcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847824eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this into seaborn to make it even cooler\n",
    "sums.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6adcd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaff040",
   "metadata": {},
   "source": [
    "Defining a function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3d674",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac8e917",
   "metadata": {},
   "source": [
    "Look at lab on https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab/tree/solution\n",
    "might need to do some one hot encoding.\n",
    "Also, just like it shows there, as a naive model maybe decrease the number of layers and keep epochs at like 5.\n",
    "If results are the same, try to understand why the loss still showes such high peaks.And why the accuracy drops like that.\n",
    "Might also be worth doing CNN from the start with 2D layers instead of this basic NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30c9434",
   "metadata": {},
   "source": [
    "Let us forget about all of this and try with the 2D actual convolutional neural network for images. The perfmormance there might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18dedf3",
   "metadata": {},
   "source": [
    "We can also do something else which is group together the types of skin abnormalities that are cancerous and the ones that are not, reducing the classes to 2 and making this a binary classification problem.\n",
    "I will do that later on. For now let's see what happens with a convolutional neural network, which is what I should be doing anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536c6537",
   "metadata": {},
   "source": [
    "Here also definitely preview one image per class and explain a bit about each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703a306d",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09c953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(32, 32), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(32, 32), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183a4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_img.shape[0]\n",
    "num_px = train_img.shape[1]\n",
    "m_test = test_img.shape[0]\n",
    "#m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "#print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_img.shape))\n",
    "print (\"train_labels shape: \" + str(train_lab.shape))\n",
    "print (\"test_images shape: \" + str(test_img.shape))\n",
    "print (\"test_labels shape: \" + str(test_lab.shape))\n",
    "#print (\"val_images shape: \" + str(val_images.shape))\n",
    "#print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aed880",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img = train_img.reshape(train_img.shape[0], -1)\n",
    "#test_img = test_img.reshape(test_img.shape[0], -1)\n",
    "#val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "#print(val_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e5e3ab",
   "metadata": {},
   "source": [
    "As we can see the RGB values of each pixel are not scaled, we are going to scale their value between 0 and 1 by dividing each pixel value by 225,\n",
    "and we are also going to reshape the data in a format that can be fed into the model.\n",
    "We are going to put these two preprocessing steps together with a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2e1f35",
   "metadata": {},
   "source": [
    "#### Here I am going to create my first pipeline \n",
    "to use to scale and reshape the data once I have loaded it\n",
    "Or possibly even a function to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd20129",
   "metadata": {},
   "source": [
    "to standardize the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bfc02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pixels(train_img, test_img, train_lab, test_lab):\n",
    "    train_img /= 255.\n",
    "    test_img /= 255.\n",
    "    return train_img, test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db71516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "pix_scaler = FunctionTransformer(scale_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723bcaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_scaler.fit_transform(train_img, test_img, train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pix_scaler.transform(train_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ea6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#StandardScaler().fit_transform(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c564ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73070d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f41eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "#scaler = MinMaxScaler()\n",
    "# Transform the training and test sets\n",
    "#scaled_data_train = scaler.fit_transform(train_img)\n",
    "#scaled_data_test = scaler.transform(test_img)\n",
    "\n",
    "# Convert into a DataFrame\n",
    "#scaled_df_train = pd.DataFrame(scaled_data_train, columns=X_train.columns)\n",
    "#scaled_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6626c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_pixels(train_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce29e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cf1321",
   "metadata": {},
   "source": [
    "To change the shape of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c9b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape (train_lab, test_lab): #(train_img, test_img, train_lab, test_lab):\n",
    "    m=train_lab.shape[0]\n",
    "    n=test_lab.shape[0]\n",
    "    train_lab = np.reshape(train_lab[:,0], (m,1))\n",
    "    test_lab = np.reshape(test_lab[:,0], (n,1))\n",
    "    return train_lab, test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "shaper = FunctionTransformer(reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86718e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lab.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y, test_y=reshape(train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b85701",
   "metadata": {},
   "outputs": [],
   "source": [
    "shaper.fit_transform(train_lab, test_lab)#(train_img, test_img, train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50857448",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lab.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25e64bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ed201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct=make_column_transformer(\n",
    "    (pix_scaler, ['img_scaled']),\n",
    "    (shaper, ['labels_reshaped']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5649b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.fit_transform(train_img, test_img, train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0062b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with StandardScaler and KNeighborsClassifier\n",
    "scale_pipeline = Pipeline([('pixel scaler', pix_scaler(train_img, test_img)),\n",
    "        ('changing shape', shaper(train_lab, test_lab))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_pipeline.fit_transform(train_img, test_img, train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f33015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda5db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    ax1.plot(history['val_acc'])\n",
    "    ax1.plot(history['acc'])\n",
    "    ax1.legend(['val_acc', 'acc'], loc='best')\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    \n",
    "    ax2.plot(history['val_loss'])\n",
    "    ax2.plot(history['loss'])\n",
    "    ax2.legend(['val_loss', 'loss'], loc='best')\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87df96",
   "metadata": {},
   "source": [
    "Creating the empty dataframe where we will store the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff25599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Empty DataFrame object\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(results, model_name, df):\n",
    "    visualize_training_results(results)\n",
    "    df1 = pd.DataFrame({'Name': [model_name],\n",
    "                        'accuracy train': [round(results.history['acc'][-1],3)] ,\n",
    "                        'accuracy validation': [round(results.history['val_acc'][-1],3 )],\n",
    "                        'loss train': [round(results.history['loss'][-1],3)],\n",
    "                        'loss validation': [round(results.history['val_loss'][-1],3)]})\n",
    "    df=df.append(df1)\n",
    "    fig = plt.subplots(figsize=(12,6))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    x=df['Name']\n",
    "    y=df['accuracy train']\n",
    "    plt.plot(x, y, color='r')\n",
    "    x1=df['Name']\n",
    "    y1=df['accuracy validation']\n",
    "    plt.plot(x1, y1, color='g')\n",
    "    plt.xticks(x, labels=df['Name'], rotation='vertical')\n",
    "    plt.title('Learning Curve Accuracy')\n",
    "    plt.legend()\n",
    "#    fig = plt.subplots(figsize=(6,6)) \n",
    "    plt.subplot(1,2,2)\n",
    "    x=df['Name']\n",
    "    y=df['loss train']\n",
    "    plt.plot(x, y, color='r')\n",
    "    x1=df['Name']\n",
    "    y1=df['loss validation']\n",
    "    plt.plot(x1, y1, color='g')\n",
    "    plt.xticks(x, labels=df['Name'], rotation='vertical')\n",
    "    plt.title('Learning Curve Loss')\n",
    "    plt.legend()\n",
    "#    sns.pointplot(x=df['Name'], y=df['accuracy train'], \n",
    "#                linestyles='dotted',data=df, ax=ax1)\n",
    "#                  hue=df[['accuracy train', 'accuracy validation']])\n",
    "#    ax1.set_xticklabels(labels=df['Name'], rotation=90)\n",
    "\n",
    "#    sns.pointplot(x=df['Name'], y=df['accuracy validation'],color='r',\n",
    "#                linestyles='dotted',data=df, ax=ax1, label='validation')\n",
    "#                  ,  hue=df['accuracy train', 'accuracy validation'].apply(tuple, axis=1))\n",
    "#    ax1.set_xticklabels(labels=df['Name'], rotation=90)\n",
    "#    ax1.set(xlabel='Model')\n",
    "#    ax1.set_title('Learning Curve Accuracy')\n",
    "\n",
    "#    plt.legend(handles=[df,df], loc='best')\n",
    "#    ax1.legend(['accuracy train', 'accuracy validation'])\n",
    "#    ax1.legend(handles=ax1.lines[::len(df1)+1], labels=['train', 'validation'])\n",
    "#    sns.pointplot(x=df['Name'], y=df['loss train'],color='b',\n",
    "#                linestyles='dotted',data=df, ax=ax2)\n",
    "#    ax2.set_xticklabels(labels=df['Name'], rotation=90)\n",
    "#    sns.pointplot(x=df['Name'], y=df['loss validation'],color='r',\n",
    "#                  linestyles='dotted',data=df, ax=ax2)\n",
    "#    ax2.set_xticklabels(labels=df['Name'], rotation=90)\n",
    "#    ax2.legend(labels=['loss train', 'loss validation'], loc='best')\n",
    "#    ax2.legend()\n",
    "#    ax2.set_title('Learning Curve Loss')\n",
    "#    ax2.set(xlabel='Model')\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd417c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history1, '32x32 1st model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0554af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_training_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd09fcd6",
   "metadata": {},
   "source": [
    "### Trying to pick a Naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef1f9db",
   "metadata": {},
   "source": [
    "Trying with a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3745e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70bc0f",
   "metadata": {},
   "source": [
    "And doing only 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629e88ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1304cab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=model_results(history1, '32x32 1st model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976fe1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with StandardScaler and KNeighborsClassifier\n",
    "#scaled_pipeline_1 = Pipeline([('ssc', StandardScaler()), ('KNN', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508c5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Fit the training data to pipeline\n",
    "scaled_pipeline_1.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy on test set\n",
    "scaled_pipeline_1.score(X_test, y_test)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5906ab79",
   "metadata": {},
   "source": [
    "Let me try with a larger batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3223995",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history2, '32x32 2nd model, larger batch', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1541095",
   "metadata": {},
   "source": [
    "Another attempt: all the previous parameters but making the last dense layer smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0605cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(10, activation='relu'))\n",
    "model2.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a73a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model2.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad303ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history3, '32x32 3rd model, < nrns last layer', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ffeab",
   "metadata": {},
   "source": [
    "Even less Neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb066c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(5, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(5, activation='relu'))\n",
    "model3.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f096daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model3.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859e663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history4, '32x32 4th model, < neurons', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dee7e8",
   "metadata": {},
   "source": [
    "#### No sorry one more thing. Even less resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169950a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(8, 8), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(8, 8), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a927049",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efbd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93f7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(8 ,8,  3)))\n",
    "model5.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29005f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = model5.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e511225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history5, '8x8 5th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517d2e92",
   "metadata": {},
   "source": [
    "Let me try to decrease the batch size already from the import, see if is changes anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbe8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(8, 8), batch_size=5)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(8, 8), batch_size=20)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51c3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (20,1))\n",
    "test_y = np.reshape(test_lab[:,0], (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84167bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model5.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07610cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history6, '8x8 5th model < batch on import', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca73595",
   "metadata": {},
   "source": [
    "The good news is that even if the results change a lot in the first part where I do regualr NN, every time I run the code, they don't change so radically with the CNN.\n",
    "I will keep track a bit but overall it seems like I can stop worrying about reproducibe results, if I use CNN right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5442ed",
   "metadata": {},
   "source": [
    "## Starting to improve our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d366900d",
   "metadata": {},
   "source": [
    "Taking from the german signs notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87482004",
   "metadata": {},
   "source": [
    "Nope. It's in AWS Sagemaker. But I can look back at it and use either a simple pipeline for loading and changing the size of the images, or for images augmentation to balance the classes of the different skin anomalies.\n",
    "<br>A simple pipeline can even be \"load, normalize, augment\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae22592",
   "metadata": {},
   "source": [
    "#### To improve our model we will take several steps:\n",
    "   - normalize the data \n",
    "   - increase image resolution\n",
    "   - add more epochs\n",
    "   - add more layers\n",
    "   - increase the batch size\n",
    "   - change activation function and optimization\n",
    "    \n",
    "After we have done all this we will select the best performing model and we will also group up into 2 classes, cancerous and benign growth too.\n",
    "<br>Maybe I should do that now actually.\n",
    "<br>No I will do it after this first selection so I can say I have a good model to predict which of the 9 classes with this much accuracy.\n",
    "<br>And then introduce the concept of two classes and decreasing recall.\n",
    "<br>After that anyhow, do another round of tuning for the model, this time using:\n",
    " - drop out layers\n",
    " - regularization\n",
    " - normalization\n",
    " - data augmentation\n",
    " - balancing classes with data augmentation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb10c631",
   "metadata": {},
   "source": [
    "### Improving the model with 9 classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a2d6a7",
   "metadata": {},
   "source": [
    "Restart with an empty dataframe because while before we were looking for the lowest performance model now we are looking to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaa5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8704467",
   "metadata": {},
   "source": [
    "Let us start by visualizing again the results from what we picked to be our naive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0fa675",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history5, 'Naive', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e0e71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f62b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a5c498",
   "metadata": {},
   "source": [
    "#### Normalize the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfe4e4d",
   "metadata": {},
   "source": [
    "To standardize the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4fd3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img /= 255.\n",
    "test_img /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80140c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history52 = model5.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45ddcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history52, '8x8 5th model scaled pixels', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e816e600",
   "metadata": {},
   "source": [
    "#### Increasing Image resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2515735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(64, 64), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(64, 64), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)\n",
    "#normalizing again\n",
    "train_img /= 255.\n",
    "test_img /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1126883",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = models.Sequential()\n",
    "model6.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "model6.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model6.add(layers.Flatten())\n",
    "model6.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model6.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6b = model6.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425c1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history6b, '64x64 6th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0348dd7",
   "metadata": {},
   "source": [
    "Let us try increasing the size of the images imported further. Let us go all the way to the actually full size which is 256. These are already loaded at the beginning and are sotred in train_images_fs, test_images_fs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c34a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing again\n",
    "train_images_fs /= 255.\n",
    "test_images_fs /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c155d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6b = models.Sequential()\n",
    "model6b.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256, 3)))\n",
    "model6b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model6b.add(layers.Flatten())\n",
    "model6b.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model6b.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e4869d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6c = model6b.fit(train_images_fs,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1cb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history6c, '256x256 6th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f2fc0",
   "metadata": {},
   "source": [
    "Let us see what happens with the full size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c37e63",
   "metadata": {},
   "source": [
    "#### Increasing number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3bc3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model6.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be7377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history7, '64x64 6th model, 30 epochs', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0fddde",
   "metadata": {},
   "source": [
    "#### Adding more layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e371b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = models.Sequential()\n",
    "model7.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Flatten())\n",
    "model7.add(layers.Dense(32, activation='relu'))\n",
    "model7.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model7.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75be84ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "history8 = model7.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9678bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history8, '64x64 7th model, 30 epochs, more layers', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057e157d",
   "metadata": {},
   "source": [
    "#### Adding more layers and higher resolution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49015380",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7b = models.Sequential()\n",
    "model7b.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(256 ,256,  3)))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Flatten())\n",
    "model7b.add(layers.Dense(32, activation='relu'))\n",
    "model7b.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model7b.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df363ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history8b = model7b.fit(train_images_fs,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3445802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history8b, '256x256 7th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3507a03f",
   "metadata": {},
   "source": [
    "#### Increase the batch size: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e43679",
   "metadata": {},
   "outputs": [],
   "source": [
    "history9 = model7.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=50, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806a00a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history9, '64x64 7th model, batch size=50', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bab4ee",
   "metadata": {},
   "source": [
    "The truth is that just getting one result for each of these attempts doesn't really tell us too much about the improvement or not of our model, because of the randomness of the results.\n",
    "What would be more appropriate is for each change we do (in the size of the images, the number of epochs, the batch size) to try a few different values to be able to really get a sense of in which direction our model is moving with that change.\n",
    "This would be very time consuming to do by hand, so the next step we are goign to take is building a grid search for these parameteres to get a better answer in terms of which ones are the optimal charateristic of our model, which gives us the best accuracy in determining the classification of the skin anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9bb383",
   "metadata": {},
   "source": [
    "### Grid Search batch size and epochs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1120f1f",
   "metadata": {},
   "source": [
    "Grid search is a model hyperparameter optimization technique.\n",
    "In scikit learn this is a class, and when running a search with this class, we must input a dictionary of hyperparameters to evaluate in the param_grid argument. \n",
    "This dictionary contains the model parameter name and an array of values to try.\n",
    "\n",
    "The GridSearchCV essentially builds and then evaluates one model for each combination of parameters. \n",
    "To evaluate each individual model, a 3-fold cross validation is used.\n",
    "\n",
    "Even if we might have seen a better result with higher resolution images, we will keep the 64x64 ones for the grid search to limit the running time of our code.\n",
    "Once we  find out from the GridSearch what are the best parameteres we can use those (running just one single model) with higher resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9322141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    " # create model\n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "#    model.add(Dense(1, activation='sigmoid'))\n",
    "    model7 = models.Sequential()\n",
    "    model7.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "    model7.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model7.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "    model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model7.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model7.add(layers.Flatten())\n",
    "    model7.add(layers.Dense(32, activation='relu'))\n",
    "    model7.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "\n",
    "# Compile model\n",
    "    model7.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "#dataset = np.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "#X = dataset[:,0:8]\n",
    "#Y = dataset[:,8]\n",
    "X=train_img\n",
    "Y=train_y\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid)#, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=paramsgrid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcd25cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out here exactly how to extract each, the epochs and batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b25079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc317ae6",
   "metadata": {},
   "source": [
    "Now we can run again a model with the higher resolution images, using the best parameters we obtained from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d66864",
   "metadata": {},
   "outputs": [],
   "source": [
    "history10 = model7b.fit(train_images_fs,\n",
    "                    train_y,\n",
    "                    epochs=best_epochs,\n",
    "                    batch_size=best_batch, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67125d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history10, 'best model 1st Gridsearch', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d14d79",
   "metadata": {},
   "source": [
    "### Grid Search Activation Functions and Optimizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77064102",
   "metadata": {},
   "source": [
    "We can run again a GridSearch, but this time instead of trying different numbers of epochs and batch sizes, we will try different activation functions and optimizations. Here are lists of both, and as we can see from the number of options, GridSearch is a good idea to shorten the time in trying all the different possible combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f011dcf8",
   "metadata": {},
   "source": [
    "#### Changing activation functions and optimizations:\n",
    "Some of the options for activation functions are:\n",
    "<br>relu\n",
    "<br>swish\n",
    "<br>softmax\n",
    "<br>leaky relu\n",
    "<br>sigmoid\n",
    "\n",
    "<br>for optimizers:\n",
    "<br>adam, sgd, \n",
    "<br>with optimizer I can also tweak the learning rate\n",
    "\n",
    "<br>for loss functions:\n",
    "categorical_crossentropy, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755bce3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6887d0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecdb91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40121e47",
   "metadata": {},
   "source": [
    "To get recall:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train=model.predict(train_img)\n",
    "y_hat_test=model.predict(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34820fc",
   "metadata": {},
   "source": [
    "Clearly here I have to round to get the actual prediction for the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493d21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0e1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "pr_train=precision_score(train_labels, train_labels, average=None)\n",
    "#rec_train=recall_score(train_labels, y_hat_train)\n",
    "#acc_train=accuracy_score(train_labels, y_hat_train)\n",
    "#f1_train=f1_score(train_labels, y_hat_train)\n",
    "\n",
    "#pr_test=precision_score(test_labels, y_hat_test)\n",
    "#rec_test=recall_score(test_labels, y_hat_test)\n",
    "#acc_test=accuracy_score(test_labels, y_hat_test)\n",
    "#f1_test=f1_score(test_labels, y_hat_test)\n",
    "pr_train\n",
    "#print(\"Train: \\nprecision\", pr_train,\"\\nrecall:\", rec_train, '\\naccuracy:', acc_train, '\\nf1 score:', f1_train,'\\n')\n",
    "#print(\"Test: \\nprecision\", pr_test,\"\\nrecall:\", rec_test, '\\naccuracy:', acc_test, '\\nf1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf06573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
