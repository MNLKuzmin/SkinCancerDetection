{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1fa9652",
   "metadata": {},
   "source": [
    "# Skin cancer detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd52e2e",
   "metadata": {},
   "source": [
    "Dataset taken from Kaggle at [Skin Cancer ISIC](https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62f54fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_digits, load_sample_images\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cb3931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 images belonging to 9 classes.\n",
      "Found 2239 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_images_fs, train_labels = next(train_generator)\n",
    "test_images_fs, test_labels = next(test_generator)\n",
    "#val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49df153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2477b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(train_images_fs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(test_images_fs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf9587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cff3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a18ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bcc6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78df8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b747f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742944c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(train_labels, columns=['actinic_keratosis', 'basal_cell_carcinoma',\\\n",
    "            'dermatofibroma', 'melanoma', 'nevus', 'pigmented_benign_keratosis',\\\n",
    "            'seborrheic_keratosis', 'squamous_cell_carcinoma', 'vascular_lesion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1a2787",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae16d713",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dba048",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=dataframe.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b164c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=pd.DataFrame(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb87d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620c6610",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums['%'] = ((sums[0] / 2239*100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c8b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51416855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change this into seaborn to make it even cooler\n",
    "sums.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c026b",
   "metadata": {},
   "source": [
    "Defining a function to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ac496",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c266a6",
   "metadata": {},
   "source": [
    "Look at lab on https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab/tree/solution\n",
    "might need to do some one hot encoding.\n",
    "Also, just like it shows there, as a naive model maybe decrease the number of layers and keep epochs at like 5.\n",
    "If results are the same, try to understand why the loss still showes such high peaks.And why the accuracy drops like that.\n",
    "Might also be worth doing CNN from the start with 2D layers instead of this basic NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ebbc55",
   "metadata": {},
   "source": [
    "Let us forget about all of this and try with the 2D actual convolutional neural network for images. The perfmormance there might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69390cb1",
   "metadata": {},
   "source": [
    "We can also do something else which is group together the types of skin abnormalities that are cancerous and the ones that are not, reducing the classes to 2 and making this a binary classification problem.\n",
    "I will do that later on. For now let's see what happens with a convolutional neural network, which is what I should be doing anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834e6bb",
   "metadata": {},
   "source": [
    "Here also definitely preview one image per class and explain a bit about each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d602276",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f099272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "#test_gen= ImageDataGenerator().flow_from_directory(\n",
    "#        test_data_dir, target_size=(32, 32), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(32, 32), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img32, train_lab = next(train_gen)\n",
    "test_img32, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cf24c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_img32.shape[0]\n",
    "num_px = train_img32.shape[1]\n",
    "m_test = test_img32.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"train_images shape: \" + str(train_img32.shape))\n",
    "print (\"train_labels shape: \" + str(train_lab.shape))\n",
    "print (\"test_images shape: \" + str(test_img32.shape))\n",
    "print (\"test_labels shape: \" + str(test_lab.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77c17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lab.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1751cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img = train_img.reshape(train_img.shape[0], -1)\n",
    "#test_img = test_img.reshape(test_img.shape[0], -1)\n",
    "#val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "#print(val_img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c7c202",
   "metadata": {},
   "source": [
    "As we can see the RGB values of each pixel are not scaled, we are going to scale their value between 0 and 1 by dividing each pixel value by 225,\n",
    "and we are also going to reshape the data in a format that can be fed into the model.\n",
    "We are going to put these two preprocessing steps together with a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c94e3df",
   "metadata": {},
   "source": [
    "#### Here I am going to create my first pipeline \n",
    "to use to scale and reshape the data once I have loaded it\n",
    "Or possibly even a function to load it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf9da49",
   "metadata": {},
   "source": [
    "to standardize the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbebab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_pixels(train_img, test_img, train_lab, test_lab):\n",
    "    train_img /= 255.\n",
    "    test_img /= 255.\n",
    "    return train_img, test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d677387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "pix_scaler = FunctionTransformer(scale_pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e667a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"pix_scaler.fit_transform(train_img32, test_img32, train_lab, test_lab)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30749e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pix_scaler.transform(train_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7982db0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#StandardScaler().fit_transform(train_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a9b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f89433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8828dbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate StandardScaler\n",
    "#scaler = MinMaxScaler()\n",
    "# Transform the training and test sets\n",
    "#scaled_data_train = scaler.fit_transform(train_img)\n",
    "#scaled_data_test = scaler.transform(test_img)\n",
    "\n",
    "# Convert into a DataFrame\n",
    "#scaled_df_train = pd.DataFrame(scaled_data_train, columns=X_train.columns)\n",
    "#scaled_df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b37a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale_pixels(train_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea57feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e73f26",
   "metadata": {},
   "source": [
    "To change the shape of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2a8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape (train_lab, test_lab): #(train_img, test_img, train_lab, test_lab):\n",
    "    m=train_lab.shape[0]\n",
    "    n=test_lab.shape[0]\n",
    "    train_lab = np.reshape(train_lab[:,0], (m,1))\n",
    "    test_lab = np.reshape(test_lab[:,0], (n,1))\n",
    "    return train_lab, test_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae22dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate transformer\n",
    "shaper = FunctionTransformer(reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29174120",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lab.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f81e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y, test_y=reshape(train_lab, test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d57f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"shaper.fit_transform(train_lab, test_lab)#(train_img, test_img, train_lab, test_lab)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410500e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_lab.shape)\n",
    "print(test_lab.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8eb2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad16863",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd709303",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ct=make_column_transformer(\n",
    "    (pix_scaler, ['img_scaled']),\n",
    "    (shaper, ['labels_reshaped']))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eceadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ct.fit_transform(train_img, test_img, train_lab, test_lab)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd80d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline with StandardScaler and KNeighborsClassifier\n",
    "\"\"\"scale_pipeline = Pipeline([('pixel scaler', pix_scaler(train_img, test_img)),\n",
    "        ('changing shape', shaper(train_lab, test_lab))])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d983eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"scale_pipeline.fit_transform(train_img, test_img, train_lab, test_lab)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91129998",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Fit the training data to pipeline\n",
    "scaled_pipeline_1.fit(X_train, y_train)\n",
    "\n",
    "# Print the accuracy on test set\n",
    "scaled_pipeline_1.score(X_test, y_test)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac1797a",
   "metadata": {},
   "source": [
    "Building two functions that will help us visualize and compare the different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f2440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    ax1.plot(history['val_acc'])\n",
    "    ax1.plot(history['acc'])\n",
    "    ax1.legend(['val_acc', 'acc'], loc='best')\n",
    "    ax1.set_title('Accuracy')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    \n",
    "    ax2.plot(history['val_loss'])\n",
    "    ax2.plot(history['loss'])\n",
    "    ax2.legend(['val_loss', 'loss'], loc='best')\n",
    "    ax2.set_title('Loss')\n",
    "    ax2.set_xlabel('Epochs')\n",
    "    ax2.set_ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eabe1a",
   "metadata": {},
   "source": [
    "Creating the empty dataframe where we will store the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21844c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an Empty DataFrame object\n",
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2968b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_results(results, model_name, df):\n",
    "    visualize_training_results(results)\n",
    "    df1 = pd.DataFrame({'Name': [model_name],\n",
    "                        'accuracy train': [round(results.history['acc'][-1],5)] ,\n",
    "                        'accuracy validation': [round(results.history['val_acc'][-1],5 )],\n",
    "                        'loss train': [round(results.history['loss'][-1],5)],\n",
    "                        'loss validation': [round(results.history['val_loss'][-1],5)]})\n",
    "    df=df.append(df1)\n",
    "    fig = plt.subplots(figsize=(12,6))\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    x=df['Name']\n",
    "    y=df['accuracy train']\n",
    "    plt.plot(x, y, color='r')\n",
    "    x1=df['Name']\n",
    "    y1=df['accuracy validation']\n",
    "    plt.plot(x1, y1, color='g')\n",
    "    plt.xticks(x, labels=df['Name'], rotation='vertical')\n",
    "    plt.title('Learning Curve Accuracy')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.subplot(1,2,2)\n",
    "    x=df['Name']\n",
    "    y=df['loss train']\n",
    "    plt.plot(x, y, color='r')\n",
    "    x1=df['Name']\n",
    "    y1=df['loss validation']\n",
    "    plt.plot(x1, y1, color='g')\n",
    "    plt.xticks(x, labels=df['Name'], rotation='vertical')\n",
    "    plt.title('Learning Curve Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3140b4e5",
   "metadata": {},
   "source": [
    "And let us create another function to generate models.\n",
    "With this function we can set all the parameters that we want, input_shape, activation function, loss, optimizer algorithm, metrics etc.\n",
    "We will also set most of these parameters as default, except for input shape, to make the execution of the function not too heavy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab0edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, activation='relu', loss='sparse_categorical_crossentropy', \n",
    "                optimizer='rmsprop',metrics=['acc'] , neur1=10, neur2=32, pool=(2,2)):\n",
    " # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(neur1, (3, 3), activation=activation,\n",
    "                        input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D(pool))\n",
    "    \n",
    "    model.add(layers.Conv2D(neur1, (4, 4), activation=activation))\n",
    "    model.add(layers.MaxPooling2D(pool))\n",
    "\n",
    "    model.add(layers.Conv2D(neur2, (3, 3), activation=activation))\n",
    "    model.add(layers.MaxPooling2D(pool))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation=activation))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "    model.compile(loss=loss,\n",
    "              optimizer=optimizer,\n",
    "              metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1091ae9",
   "metadata": {},
   "source": [
    "And one more function to fit the model and get the results. Also here we can set number of epochs, batch size and validation split, but there are default parameters too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097546cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, train, y, epo=10, batch=10, val_split=0.3):\n",
    "    results = model.fit(train, y, epochs=epochs, batch_size=batch, validation_split=val_split)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_training_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a45ad",
   "metadata": {},
   "source": [
    "**Let me try them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod1=create_model((32,32,3), neurons1=15, neurons2=20 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54827757",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=fit_model(mod1, train_img32, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e455e4",
   "metadata": {},
   "source": [
    "### Trying to pick a Naive model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7165f0",
   "metadata": {},
   "source": [
    "Trying with a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83d534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2085ab1",
   "metadata": {},
   "source": [
    "And doing only 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f972f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history1 = model.fit(train_img32,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c1ff9",
   "metadata": {},
   "source": [
    "Let us visualize the results of this first model:\n",
    "The bottom two graphs will make sense only later on since we are building a learning curve, to compare the different models' performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e2eaa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=model_results(history1, '32x32 1st model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9b2151",
   "metadata": {},
   "source": [
    "Another attempt: all the previous parameters but making the last dense layer smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(10, activation='relu'))\n",
    "model2.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37880203",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model2.fit(train_img32,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32df635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history3, '32x32 3rd model, < nrns last layer', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27093fa",
   "metadata": {},
   "source": [
    "#### Even less Neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(5, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(5, activation='relu'))\n",
    "model3.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ab7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model3.fit(train_img32,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafc7f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history4, '32x32 4th model, < neurons', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9da23d",
   "metadata": {},
   "source": [
    "#### Less resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe4d9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "#test_data_dir = 'dataskin/Test'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "#test_gen= ImageDataGenerator().flow_from_directory(\n",
    "#        test_data_dir, target_size=(8, 8), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(8, 8), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img8, train_lab = next(train_gen)\n",
    "#test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f5b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3325fcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118e8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(8 ,8,  3)))\n",
    "model5.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcd5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = model5.fit(train_img8,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6432a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history5, '8x8 5th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc5b4f",
   "metadata": {},
   "source": [
    "[Let me try to decrease the batch size already from the import, see if is changes anything.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(8, 8), batch_size=5)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(8, 8), batch_size=20)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc64b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = np.reshape(train_lab[:,0], (20,1))\n",
    "#test_y = np.reshape(test_lab[:,0], (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9797d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history6 = model5.fit(train_img,\n",
    "#                    train_y,\n",
    "#                    epochs=10,\n",
    "#                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75520018",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=model_results(history6, '8x8 5th model < batch on import', df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ff39ae",
   "metadata": {},
   "source": [
    "The good news is that even if the results change a lot in the first part where I do regualr NN, every time I run the code, they don't change so radically with the CNN.\n",
    "I will keep track a bit but overall it seems like I can stop worrying about reproducibe results, if I use CNN right away."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b4d3c",
   "metadata": {},
   "source": [
    "## Starting to improve our model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d68c18",
   "metadata": {},
   "source": [
    "Taking from the german signs notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd36d2dd",
   "metadata": {},
   "source": [
    "Nope. It's in AWS Sagemaker. But I can look back at it and use either a simple pipeline for loading and changing the size of the images, or for images augmentation to balance the classes of the different skin anomalies.\n",
    "<br>A simple pipeline can even be \"load, normalize, augment\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498e723",
   "metadata": {},
   "source": [
    "#### To improve our model we will take several steps:\n",
    "   - normalize the data \n",
    "   - increase image resolution\n",
    "   - add more epochs\n",
    "   - add more layers\n",
    "   - increase the batch size\n",
    "   - change activation function and optimization\n",
    "    \n",
    "After we have done all this we will select the best performing model and we will also group up into 2 classes, cancerous and benign growth too.\n",
    "<br>Maybe I should do that now actually.\n",
    "<br>No I will do it after this first selection so I can say I have a good model to predict which of the 9 classes with this much accuracy.\n",
    "<br>And then introduce the concept of two classes and decreasing recall.\n",
    "<br>After that anyhow, do another round of tuning for the model, this time using:\n",
    " - drop out layers\n",
    " - regularization\n",
    " - normalization\n",
    " - data augmentation\n",
    " - balancing classes with data augmentation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc1e6fa",
   "metadata": {},
   "source": [
    "### Improving the model with 9 classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ddb4bb",
   "metadata": {},
   "source": [
    "Restart with an empty dataframe because while before we were looking for the lowest performance model now we are looking to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bff5cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a21e31",
   "metadata": {},
   "source": [
    "Let us start by visualizing again the results from what we picked to be our naive model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951dd6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history5, 'Naive', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d856a0",
   "metadata": {},
   "source": [
    "#### Normalize the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181621c0",
   "metadata": {},
   "source": [
    "To standardize the pixel values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb8e5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img8 /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5711247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a6c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "history52 = model5.fit(train_img8,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52858e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history52, '8x8 5th model scaled pixels', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2492fa03",
   "metadata": {},
   "source": [
    "#### Increasing Image resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "#test_data_dir = 'dataskin/Test'\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(64, 64), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img64, train_lab = next(train_gen)\n",
    "#test_img64, test_lab = next(test_gen)\n",
    "\n",
    "#normalizing again\n",
    "train_img64 /= 255.\n",
    "#test_img64 /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c36ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = models.Sequential()\n",
    "model6.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "model6.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model6.add(layers.Flatten())\n",
    "model6.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model6.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e1536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6b = model6.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33ee93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history6b, '64x64 6th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81470788",
   "metadata": {},
   "source": [
    "Let us try increasing the size of the images imported further. Let us go all the way to the actually full size which is 256. These are already loaded at the beginning and are sotred in train_images_fs, test_images_fs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d323b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing again\n",
    "train_images_fs /= 255.\n",
    "test_images_fs /= 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969c32c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6b = models.Sequential()\n",
    "model6b.add(layers.Conv2D(3, (3, 3), activation='relu',\n",
    "                        input_shape=(256, 256, 3)))\n",
    "model6b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model6b.add(layers.Flatten())\n",
    "model6b.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model6b.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b9e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6c = model6b.fit(train_images_fs,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8344f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history6c, '256x256 6th model', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75318d6",
   "metadata": {},
   "source": [
    "Let us see what happens with the full size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a53764b",
   "metadata": {},
   "source": [
    "#### Increasing number of epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59f2d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "history7 = model6.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history7, '64x64 6th model, 30 epochs', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527d85a",
   "metadata": {},
   "source": [
    "#### Adding more layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = models.Sequential()\n",
    "model7.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model7.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7.add(layers.Flatten())\n",
    "model7.add(layers.Dense(32, activation='relu'))\n",
    "model7.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model7.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history8 = model7.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history8, '64x64 7th model, 30 epochs, more layers', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad0619f",
   "metadata": {},
   "source": [
    "#### Adding more layers and higher resolution images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88976b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7b = models.Sequential()\n",
    "model7b.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(256 ,256,  3)))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model7b.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model7b.add(layers.Flatten())\n",
    "model7b.add(layers.Dense(32, activation='relu'))\n",
    "model7b.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model7b.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e46b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history8b = model7b.fit(train_images_fs,\n",
    "#                    train_y,\n",
    "#                    epochs=30,\n",
    "#                    batch_size=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a077a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=model_results(history8b, '256x256 7th model', df)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35900b12",
   "metadata": {},
   "source": [
    "#### Increase the batch size: 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8ec88",
   "metadata": {},
   "outputs": [],
   "source": [
    "history9 = model7.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=50, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1323d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history9, '64x64 7th model, batch size=50', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1481531",
   "metadata": {},
   "source": [
    "The truth is that just getting one result for each of these attempts doesn't really tell us too much about the improvement or not of our model, because of the randomness of the results.\n",
    "What would be more appropriate is for each change we do (in the size of the images, the number of epochs, the batch size) to try a few different values to be able to really get a sense of in which direction our model is moving with that change.\n",
    "This would be very time consuming to do by hand, so the next step we are goign to take is building a grid search for these parameteres to get a better answer in terms of which ones are the optimal charateristic of our model, which gives us the best accuracy in determining the classification of the skin anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431b8aa0",
   "metadata": {},
   "source": [
    "### Grid Search batch size and epochs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63935b93",
   "metadata": {},
   "source": [
    "Grid search is a model hyperparameter optimization technique.\n",
    "In scikit learn this is a class, and when running a search with this class, we must input a dictionary of hyperparameters to evaluate in the param_grid argument. \n",
    "This dictionary contains the model parameter name and an array of values to try.\n",
    "\n",
    "The GridSearchCV essentially builds and then evaluates one model for each combination of parameters. \n",
    "To evaluate each individual model, a 3-fold cross validation is used.\n",
    "\n",
    "Even if we might have seen a better result with higher resolution images, we will keep the 64x64 ones for the grid search to limit the running time of our code.\n",
    "Once we  find out from the GridSearch what are the best parameteres we can use those (running just one single model) with higher resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2209a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    " # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee17a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set X and Y\n",
    "X=train_img64\n",
    "Y=train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8221941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc9839",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=grid_result.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b4bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_batch=grid_result.best_params_['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b147f367",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epochs=grid_result.best_params_['epochs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f58d9b",
   "metadata": {},
   "source": [
    "Now we can run again a model with the higher resolution images, using the best parameters we obtained from the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3286a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history10 = model7.fit(train_images64,\n",
    "                    train_y,\n",
    "                    epochs=best_epochs,\n",
    "                    batch_size=best_batch, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history10, 'best model 1st Gridsearch', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efaf11b",
   "metadata": {},
   "source": [
    "### Grid Search Optimization Algorithm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57995cf",
   "metadata": {},
   "source": [
    "We can run again a GridSearch, but this time instead of trying different numbers of epochs and batch sizes, we will try different optimization algorithms. Here is a lists of them, and as we can see from the number of options, GridSearch is a good idea to shorten the time in trying all the different possible combinations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f642a",
   "metadata": {},
   "source": [
    "#### Changing activation functions and optimizations:\n",
    "Some of the options for activation functions are:\n",
    "<br>relu\n",
    "<br>swish\n",
    "<br>softmax\n",
    "<br>leaky relu\n",
    "<br>sigmoid\n",
    "\n",
    "<br>for optimizers:\n",
    "<br>adam, sgd, \n",
    "<br>with optimizer I can also tweak the learning rate\n",
    "\n",
    "<br>for loss functions:\n",
    "categorical_crossentropy, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786e35b2",
   "metadata": {},
   "source": [
    "We already have the function to create the model, and the X and Y we set before are teh same. We just need to change the grid for the search of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93b49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(model=create_model, \n",
    "                        loss=\"sparse_categorical_crossentropy\", \n",
    "                        epochs=best_epochs, batch_size=best_batch)\n",
    "# define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a383d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926e3c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=grid_result.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331fa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_opti=grid_result.best_params_['optimizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419722bc",
   "metadata": {},
   "source": [
    "Creating a new model with the selected optimizer algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddffe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # create model\n",
    "model8 = models.Sequential()\n",
    "model8.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(64,64, 3)))\n",
    "model8.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "model8.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model8.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model8.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model8.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model8.add(layers.Flatten())\n",
    "model8.add(layers.Dense(32, activation='relu'))\n",
    "model8.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model8.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=best_opti,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dd6636",
   "metadata": {},
   "outputs": [],
   "source": [
    "history11 = model8.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=best_epochs,\n",
    "                    batch_size=best_batch, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e3281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history11, 'best model Gridsearch optimization', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb25d93",
   "metadata": {},
   "source": [
    "### Grid Search Learning Rate and Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84975c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to add here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace47aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for learning rate and momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18509cc0",
   "metadata": {},
   "source": [
    "We could also do a grid search to choose the best activation function, but it doesn't make much sense in our multiclass case because the most popular one is softmax for this case, there aren't really that many options. But we will do this type of grid search later when we will reduce our problem to a binary classification problem, and there will be more options of activation fucntions to use at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244debc2",
   "metadata": {},
   "source": [
    "What we can still tune though is the number of neurons in the hidden layers.\n",
    "We will do this with another grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350d3364",
   "metadata": {},
   "source": [
    "### Grid Search number of neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(neurons):\n",
    " # create model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(neurons, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(layers.Conv2D(neurons, (4, 4), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Conv2D(neurons, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=best_opti,\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "#set X and Y\n",
    "X=train_img64\n",
    "Y=train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a74cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(model=create_model, epochs=best_epochs, batch_size=best_batch)\n",
    "# define the grid search parameters\n",
    "neurons = [5, 10, 20, 30]\n",
    "param_grid = dict(model__neurons=neurons)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654de99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c762e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons=grid_result.best_params_['model__neurons']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586b457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model9 = models.Sequential()\n",
    "model9.add(layers.Conv2D(neurons, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "model9.add(layers.Conv2D(neurons, (4, 4), activation='relu'))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "model9.add(layers.Conv2D(neurons, (3, 3), activation='relu'))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "model9.add(layers.Flatten())\n",
    "model9.add(layers.Dense(32, activation='relu'))\n",
    "model9.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model9.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=best_opti,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531dc68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history12 = model9.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=best_epochs,\n",
    "                    batch_size=best_batch, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c10d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history11, 'best model Gridsearch neurons', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d662fad",
   "metadata": {},
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e826a8e",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7dee63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "model9 = models.Sequential()\n",
    "model9.add(layers.Conv2D(neurons, (3, 3), activation='relu',\n",
    "                        input_shape=(64, 64, 3)))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "model9.add(layers.Conv2D(neurons, (4, 4), activation='relu',\n",
    "                         kernel_regularizer=regularizers.L2(l2=0.05)))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "model9.add(layers.Conv2D(neurons, (3, 3), activation='relu', \n",
    "                        kernel_regularizer=regularizers.L2(l2=0.05)))\n",
    "model9.add(layers.MaxPooling2D((2, 2)))\n",
    "model9.add(layers.Flatten())\n",
    "model9.add(layers.Dense(32, activation='relu', \n",
    "                       kernel_regularizer=regularizers.L2(l2=0.05)))\n",
    "model9.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model9.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=best_opti,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2cf0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "history13 = model9.fit(train_img64,\n",
    "                    train_y,\n",
    "                    epochs=best_epochs,\n",
    "                    batch_size=best_batch, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e07a125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=model_results(history11, 'after regularization', df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29347b4",
   "metadata": {},
   "source": [
    ">Look into L1 and see if it makes sense to do L1 regularization too.\n",
    ">Play also around a bit and find the best parameters for L1 and L2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fbd055",
   "metadata": {},
   "source": [
    "### Dropout Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce0727",
   "metadata": {},
   "source": [
    ">Check out grid search blogpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926f6131",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d6a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "912def07",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5d22e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb2434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31725179",
   "metadata": {},
   "source": [
    "#### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00094c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ba73cde",
   "metadata": {},
   "source": [
    "#### Testing on the test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f04c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007b0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1343e258",
   "metadata": {},
   "source": [
    "## Changing to two classes cancerous and bening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e81a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52835d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce29ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is an imbalance re balance the classes with augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957104c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_train=model.predict(train_img)\n",
    "y_hat_test=model.predict(test_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bde7f2",
   "metadata": {},
   "source": [
    "Clearly here I have to round to get the actual prediction for the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85259752",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_train=precision_score(train_labels, train_labels, average=None)\n",
    "#rec_train=recall_score(train_labels, y_hat_train)\n",
    "#acc_train=accuracy_score(train_labels, y_hat_train)\n",
    "#f1_train=f1_score(train_labels, y_hat_train)\n",
    "\n",
    "#pr_test=precision_score(test_labels, y_hat_test)\n",
    "#rec_test=recall_score(test_labels, y_hat_test)\n",
    "#acc_test=accuracy_score(test_labels, y_hat_test)\n",
    "#f1_test=f1_score(test_labels, y_hat_test)\n",
    "pr_train\n",
    "#print(\"Train: \\nprecision\", pr_train,\"\\nrecall:\", rec_train, '\\naccuracy:', acc_train, '\\nf1 score:', f1_train,'\\n')\n",
    "#print(\"Test: \\nprecision\", pr_test,\"\\nrecall:\", rec_test, '\\naccuracy:', acc_test, '\\nf1 score:', f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f845499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to compare the models (similar to previous one but comparing recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b9df8",
   "metadata": {},
   "source": [
    "### Re tuning of the parameters\n",
    "With this time binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6a786f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb9bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0de73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning with normalization and regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefd7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323e8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe009a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ad9771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b718999b",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c3479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15228c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a52bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf4752b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
