{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3206e4f5",
   "metadata": {},
   "source": [
    "Skin cancer detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57db9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.datasets import load_digits, load_sample_images\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea93b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 118 images belonging to 9 classes.\n",
      "Found 2239 images belonging to 9 classes.\n"
     ]
    }
   ],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, batch_size=2239)\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "#val_generator = ImageDataGenerator().flow_from_directory(\n",
    "#        val_data_dir, classes=['test'])\n",
    "\n",
    "# Create the datasets\n",
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "#val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dfa669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview an image\n",
    "array_to_img(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fc6045",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840f780",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c319779",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774db51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ef9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ee4f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7f22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.DataFrame(train_labels, columns=['actinic_keratosis', 'basal_cell_carcinoma',\\\n",
    "            'dermatofibroma', 'melanoma', 'nevus', 'pigmented_benign_keratosis',\\\n",
    "            'seborrheic_keratosis', 'squamous_cell_carcinoma', 'vascular_lesion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf1637f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e71650",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=dataframe.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686aad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums=pd.DataFrame(sums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bef744",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19e05e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums['%'] = ((sums[0] / 2239*100).round(2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb5a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898596d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.class_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (2239,1))\n",
    "test_y = np.reshape(test_labels[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227db12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train_img\n",
    "y=train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e470868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.add(layers.Flatten())\n",
    "model1.add(Dense(24, activation='relu', input_shape=(196608,)))\n",
    "model1.add(Dense(12, activation='relu'))\n",
    "model1.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f5b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d698b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model1.fit(X, y, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16e38af",
   "metadata": {},
   "source": [
    "The model did very well almost right away, 95% accuracy already at the fourth epoch.\n",
    "Let us explore a bit more loss and accuracy using also a validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379180c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = model1.fit(X, y, epochs=20, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39702972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff34db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434799b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97993caa",
   "metadata": {},
   "source": [
    "I just want to see out of curiosity what is the performance, with the same exact parameters, if I were to import the images in a smaller size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab6df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator64 = ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(64, 64), batch_size=10)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator64 = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(64, 64), batch_size=20)\n",
    "\n",
    "\n",
    "# Create the datasets\n",
    "train_images64, train_labels64 = next(train_generator64)\n",
    "test_images64, test_labels64 = next(test_generator64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29e52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img64 = train_images64.reshape(train_images64.shape[0], -1)\n",
    "test_img64 = test_images64.reshape(test_images64.shape[0], -1)\n",
    "print(train_img64.shape)\n",
    "print(test_img64.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y64 = np.reshape(train_labels64[:,0], (20,1))\n",
    "test_y64 = np.reshape(test_labels64[:,0], (10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec461fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X64=train_img64\n",
    "y64=train_y64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb682a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.add(Dense(24, activation='relu', input_shape=(12288,)))\n",
    "model2.add(Dense(12, activation='relu'))\n",
    "model2.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d55be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50274104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.fit(X64, y64, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e86337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = model2.fit(X64, y64, epochs=5, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc61b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99216f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e4cc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = results2.history\n",
    "history2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aa7258",
   "metadata": {},
   "source": [
    "Look at lab on https://github.com/learn-co-curriculum/dsc-image-classification-with-mlps-lab/tree/solution\n",
    "might need to do some one hot encoding.\n",
    "Also, just like it shows there, as a naive model maybe decrease the number of layers and keep epochs at like 5.\n",
    "If results are the same, try to understand why the loss still showes such high peaks.And why the accuracy drops like that.\n",
    "Might also be worth doing CNN from the start with 2D layers instead of this basic NN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d723ac",
   "metadata": {},
   "source": [
    "### Maybe another possible naive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c125f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(12, activation='tanh', input_shape=(12288,)))\n",
    "model3.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65336e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279d7609",
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = model3.fit(X64, y64, epochs=5, batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae62d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f421a26f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778d6acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing batch size to 1\n",
    "results4 = model3.fit(X64, y64, epochs=5, batch_size=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e452e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing batch size to 20\n",
    "results5 = model3.fit(X64, y64, epochs=5, batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3136e112",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a88628",
   "metadata": {},
   "source": [
    "One more attempt at a naive model:\n",
    "<br>since these ones keep performing even too well.\n",
    "<br>I decrease again the size of the images, batch size and also number of neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111622e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (132 images), and reshape them\n",
    "test_generator32= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(32, 32), batch_size=5)\n",
    "\n",
    "# Get all the data in the directory data/train (790 images), and reshape them\n",
    "train_generator32 = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(32, 32), batch_size=10)\n",
    "\n",
    "\n",
    "# Create the datasets\n",
    "train_images32, train_labels32 = next(train_generator32)\n",
    "test_images32, test_labels32 = next(test_generator32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ca7493",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img32 = train_images32.reshape(train_images32.shape[0], -1)\n",
    "test_img32 = test_images32.reshape(test_images32.shape[0], -1)\n",
    "print(train_img32.shape)\n",
    "print(test_img32.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64931dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y32 = np.reshape(train_labels32[:,0], (10,1))\n",
    "test_y32 = np.reshape(test_labels32[:,0], (5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d3fb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X32=train_img32\n",
    "y32=train_y32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ce9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.add(Dense(11, activation='relu', input_shape=(3072,)))\n",
    "model6.add(Dense(10, activation='relu'))\n",
    "model6.add(Dense(9, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5a40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d496667",
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = model6.fit(X32, y32, epochs=5, batch_size=5, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7321e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684cb4c2",
   "metadata": {},
   "source": [
    "Even better, this does not make any sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2492e0",
   "metadata": {},
   "source": [
    "Let us forget about all of this and try with the 2D actual convolutional neural network for images. The perfmormance there might be different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1533001",
   "metadata": {},
   "source": [
    "We can also do something else which is group together the types of skin abnormalities that are cancerous and the ones that are not, reducing the classes to 2 and making this a binary classification problem.\n",
    "I will do that later on. For now let's see what happens with a convolutional neural network, which is what I should be doing anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132ad54",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995edb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(32, 32), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(32, 32), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_img.shape[0]\n",
    "num_px = train_img.shape[1]\n",
    "m_test = test_img.shape[0]\n",
    "#m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "#print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_img.shape))\n",
    "print (\"train_labels shape: \" + str(train_lab.shape))\n",
    "print (\"test_images shape: \" + str(test_img.shape))\n",
    "print (\"test_labels shape: \" + str(test_lab.shape))\n",
    "#print (\"val_images shape: \" + str(val_images.shape))\n",
    "#print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120c3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_img = train_img.reshape(train_img.shape[0], -1)\n",
    "#test_img = test_img.reshape(test_img.shape[0], -1)\n",
    "#val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "#print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106152ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19933a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "#                         input_shape=(3072)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d4a133",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=30,\n",
    "                    batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc29232",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    plt.figure()\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.plot(history['acc'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f89d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219de15",
   "metadata": {},
   "source": [
    "Trying with an even more simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74d6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(layers.Conv2D(10, (4, 4), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "#model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(32, activation='relu'))\n",
    "model2.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948f4a5",
   "metadata": {},
   "source": [
    "And doing only 10 epochs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f1167",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecec055",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e288fd",
   "metadata": {},
   "source": [
    "Let me try with a larger batch size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69768d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history3 = model2.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302fa78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292f46ea",
   "metadata": {},
   "source": [
    "Last attempt: all the previous parameters but making the last dense layer smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3274e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = models.Sequential()\n",
    "model3.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model3.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model3.add(layers.Flatten())\n",
    "model3.add(layers.Dense(10, activation='relu'))\n",
    "model3.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model3.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f02f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "history4 = model3.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3fa15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37360da1",
   "metadata": {},
   "source": [
    "Even less Neurons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bae9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Conv2D(5, (3, 3), activation='relu',\n",
    "                        input_shape=(32 ,32,  3)))\n",
    "model4.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model4.add(layers.Flatten())\n",
    "model4.add(layers.Dense(5, activation='relu'))\n",
    "model4.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model4.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e331ced2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history5 = model4.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b4c62",
   "metadata": {},
   "source": [
    "No that doesn't change. Ok.\n",
    "Let's move on and try to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aaae95",
   "metadata": {},
   "source": [
    "#### No sorry one more thing. Even less resolution images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd802554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory path\n",
    "train_data_dir = 'dataskin/Train'\n",
    "test_data_dir = 'dataskin/Test'\n",
    "#val_data_dir = 'dataset/validation_set'\n",
    "\n",
    "# Get all the data in the directory data/validation (118 images), and reshape them\n",
    "test_gen= ImageDataGenerator().flow_from_directory(\n",
    "        test_data_dir, target_size=(16, 16), batch_size=118)\n",
    "\n",
    "# Get all the data in the directory data/train (2239 images), and reshape them\n",
    "train_gen = ImageDataGenerator().flow_from_directory(\n",
    "        train_data_dir, target_size=(16, 16), batch_size=2239)\n",
    "\n",
    "# Create the datasets\n",
    "train_img, train_lab = next(train_gen)\n",
    "test_img, test_lab = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_img.shape[0]\n",
    "num_px = train_img.shape[1]\n",
    "m_test = test_img.shape[0]\n",
    "#m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "#print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_img.shape))\n",
    "print (\"train_labels shape: \" + str(train_lab.shape))\n",
    "print (\"test_images shape: \" + str(test_img.shape))\n",
    "print (\"test_labels shape: \" + str(test_lab.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_lab[:,0], (2239,1))\n",
    "test_y = np.reshape(test_lab[:,0], (118,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7557475",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = models.Sequential()\n",
    "model5.add(layers.Conv2D(10, (3, 3), activation='relu',\n",
    "                        input_shape=(16 ,16,  3)))\n",
    "model5.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model5.add(layers.Flatten())\n",
    "model5.add(layers.Dense(10, activation='relu'))\n",
    "model5.add(layers.Dense(9, activation='softmax'))\n",
    "\n",
    "model5.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e103e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history6 = model5.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f9a412",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(history5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec681206",
   "metadata": {},
   "source": [
    "### Starting to improve our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97359650",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9abbff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f2a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d96bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580eb70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde419c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3e9abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
